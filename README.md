# Breast-cancer
El objetivo del proyecto es **predecir si un tumor es benigno o maligno**, a partir de caracter√≠sticas morfol√≥gicas obtenidas de muestras celulares.

---

## üìä Dataset

üì¶ Fuente: [Breast Cancer Wisconsin (Diagnostic) Dataset ‚Äì UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))

El dataset contiene informaci√≥n sobre caracter√≠sticas microsc√≥picas de c√©lulas tumorales, utilizadas para determinar la naturaleza del tumor.

**Variables principales:**
- `Cl.thickness` ‚Äì Grosor de las c√©lulas epiteliales  
- `Cell.size` ‚Äì Tama√±o de las c√©lulas  
- `Cell.shape` ‚Äì Forma de las c√©lulas  
- `Marg.adhesion` ‚Äì Adhesi√≥n marginal  
- `Epith.c.size` ‚Äì Tama√±o de c√©lulas epiteliales  
- `Bare.nuclei` ‚Äì N√∫cleos desnudos  
- `Bland.chromatin` ‚Äì Cromatina blanda  
- `Normal.nucleoli` ‚Äì Presencia de nucl√©olos normales  
- `Mitoses` ‚Äì Tasa de mitosis  
- `Class` ‚Äì Variable objetivo (`benign` / `malignant`)

---

## üßπ Limpieza de datos

- Sin **valores faltantes significativos**  
- Se normalizaron variables num√©ricas para mejorar el desempe√±o del modelo  
- Se eliminaron duplicados y se codific√≥ la variable objetivo como binaria (0 = benigno, 1 = maligno)

---

## üîç Insights Principales

- Tumores con valores **altos de `Cl.thickness`, `Cell.size`, `Marg.adhesion`, `Epith.c.size`, `Bare.nuclei`, `Bland.chromatin`, `Normal.nucleoli` y `Mitoses`** tienen mayor probabilidad de ser **malignos**.  
- Las variables **`Bare.nuclei`** y **`Cl.thickness`** son las m√°s determinantes seg√∫n la importancia del modelo.  
- No hay diferencias significativas entre muestras por paciente, lo que sugiere un dataset bien balanceado.
 ![Boxplot](Boxplots.png)

---

## ü§ñ Modelado Predictivo

Se probaron distintos modelos de clasificaci√≥n supervisada.

**Mejor modelo:** `Gradient Boosting`

| Modelo | Accuracy | Precision | Recall | F1 Score |
|---------|-----------|-----------|---------|-----------|
| Gradient Boosting | **0.985** | **1.00** | 0.97 | 0.985 |

Otros modelos evaluados: Logistic Regression, Random Forest, SVM, XGBoost.

---

## üß∞ Tecnolog√≠as utilizadas

- **Lenguaje:** Python  
- **Bibliotecas:** `pandas`, `numpy`, `matplotlib`, `seaborn`, `scikit-learn`, `xgboost`  
- **T√©cnicas:**  
  - Normalizaci√≥n de datos  
  - Feature importance  
  - Validaci√≥n cruzada  
  - Evaluaci√≥n de m√©tricas de clasificaci√≥n (Precision, Recall, F1, ROC AUC)  
  - Visualizaci√≥n de resultados  

---
